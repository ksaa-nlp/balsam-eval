# A function to normalize strings to id like format (normalized and sanitized to be used as a file name too)
import unicodedata
"""A module for working with tasks and datasets."""

import json
import os
from typing import Any


from google.cloud import storage

def normalize_string(text: str) -> str:
    return (
        unicodedata.normalize("NFKC", text)
        .lower()
        .replace("\x00", "")
        .strip()
        [:255]
        .replace(" ", "_")
        .replace(".", "_")
        .replace("/", "_")
    )
    
def download_dataset_from_gcs(dataset_id: str, directory: str) -> dict[str, Any]:
    """
    Download a dataset from GCS. The dataset is identified by a dataset ID
    which corresponds to its primary key in the database.
    """
    storage_client = storage.Client()
    bucket_name = os.getenv("GCLOUD_BUCKET")
    bucket = storage_client.bucket(bucket_name)
    # Create a temporary directory to store the dataset
    os.makedirs(directory, exist_ok=True)
    blob = bucket.blob(f"datasets/{dataset_id}.json")
    blob.download_to_filename(f".temp/{dataset_id}.json")

    print(f"Downloaded {dataset_id}.json from GCS bucket.")

    # Read the dataset from the file
    with open(f".temp/{dataset_id}.json", "r", encoding="utf8") as fp:
        dataset = json.load(fp)
        dd = dataset["json"]
        dd["task"] = dataset["task"]
        dd["category"] = dataset["category"]
        # Overwrite the dataset with the new data
        with open(f".temp/{dataset_id}.json", "w", encoding="utf8") as fp:
            json.dump(dd, fp, ensure_ascii=False)
        return dd


def mcq_custom_prompt():
    return '''
You are an impartial and expert evaluator for a multiple-choice question.
 
You will be given two pieces of information:
1. The gold (correct) answer.
2. The answer generated by the model.
 
Your task is to determine whether the generated answer is correct.
 
**Evaluation Rules:**
- Assign a score of **1** if any of the following conditions hold:
  - The generated answer matches the gold answer **by letter**, including **Arabic–English equivalence** (e.g., "A" = "أ", "B" = "ب", "C" = "ج", "D" = "د", "E" = "هـ", "F" = "و").
  - The generated answer matches the gold answer **by choice text** (e.g., both are "1/4").
  - The answers correspond to **yes/no equivalents**, where ("yes" = "نعم") and ("no" = "لا").
- Otherwise, assign a score of **0**.
 
Ignore differences in capitalization, spacing, punctuation, and script (Arabic or Latin).
 
**Output Format:**
Return only a JSON object with:
1. `score`: 1 if correct, 0 if incorrect.
2. `explanation`: A concise reason explaining why the answer is correct or incorrect.
 
**Example Output JSON:**
 
{
  "score": 1,
  "explanation": "The generated answer matches the correct choice considering Arabic-English and yes/no equivalences."
}'''